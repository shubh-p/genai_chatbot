[
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "google.generativeai",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "retrieve_context",
        "importPath": "core.retrieval_langchain",
        "description": "core.retrieval_langchain",
        "isExtraImport": true,
        "detail": "core.retrieval_langchain",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "core.logging_config",
        "description": "core.logging_config",
        "isExtraImport": true,
        "detail": "core.logging_config",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "core.logging_config",
        "description": "core.logging_config",
        "isExtraImport": true,
        "detail": "core.logging_config",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "requests",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "requests",
        "description": "requests",
        "detail": "requests",
        "documentation": {}
    },
    {
        "label": "BeautifulSoup",
        "importPath": "bs4",
        "description": "bs4",
        "isExtraImport": true,
        "detail": "bs4",
        "documentation": {}
    },
    {
        "label": "SentenceTransformer",
        "importPath": "sentence_transformers",
        "description": "sentence_transformers",
        "isExtraImport": true,
        "detail": "sentence_transformers",
        "documentation": {}
    },
    {
        "label": "SentenceTransformer",
        "importPath": "sentence_transformers",
        "description": "sentence_transformers",
        "isExtraImport": true,
        "detail": "sentence_transformers",
        "documentation": {}
    },
    {
        "label": "logging",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "logging",
        "description": "logging",
        "detail": "logging",
        "documentation": {}
    },
    {
        "label": "FAISS",
        "importPath": "langchain.vectorstores",
        "description": "langchain.vectorstores",
        "isExtraImport": true,
        "detail": "langchain.vectorstores",
        "documentation": {}
    },
    {
        "label": "HuggingFaceEmbeddings",
        "importPath": "langchain.embeddings",
        "description": "langchain.embeddings",
        "isExtraImport": true,
        "detail": "langchain.embeddings",
        "documentation": {}
    },
    {
        "label": "Document",
        "importPath": "langchain.docstore.document",
        "description": "langchain.docstore.document",
        "isExtraImport": true,
        "detail": "langchain.docstore.document",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "argparse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "argparse",
        "description": "argparse",
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "pformat",
        "importPath": "pprint",
        "description": "pprint",
        "isExtraImport": true,
        "detail": "pprint",
        "documentation": {}
    },
    {
        "label": "jmespath",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "jmespath",
        "description": "jmespath",
        "detail": "jmespath",
        "documentation": {}
    },
    {
        "label": "exceptions",
        "importPath": "jmespath",
        "description": "jmespath",
        "isExtraImport": true,
        "detail": "jmespath",
        "documentation": {}
    },
    {
        "label": "streamlit",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "streamlit",
        "description": "streamlit",
        "detail": "streamlit",
        "documentation": {}
    },
    {
        "label": "generate_response",
        "importPath": "core.chatbot_core_gemini",
        "description": "core.chatbot_core_gemini",
        "isExtraImport": true,
        "detail": "core.chatbot_core_gemini",
        "documentation": {}
    },
    {
        "label": "generate_response",
        "kind": 2,
        "importPath": "core.chatbot_core_gemini",
        "description": "core.chatbot_core_gemini",
        "peekOfCode": "def generate_response(query):\n    # Retrieve relevant context for the query\n    context = retrieve_context(query)\n    # Log the query and context for debugging\n    logger.info(f\"Query: {query}\")\n    logger.info(f\"Retrieved Context: {context}\")\n    # Format the prompt to limit the response to the context\n    formatted_prompt = (\n        f\"Use only the information provided in the following context to answer the query.\\n\\n\"\n        f\"Context:\\n{context}\\n\\n\"",
        "detail": "core.chatbot_core_gemini",
        "documentation": {}
    },
    {
        "label": "genai_api_key",
        "kind": 5,
        "importPath": "core.chatbot_core_gemini",
        "description": "core.chatbot_core_gemini",
        "peekOfCode": "genai_api_key = os.getenv('GEMINI_API_KEY')\ngenai.configure(api_key=genai_api_key)\nmodel = genai.GenerativeModel(\"gemini-1.5-flash\")\ndef generate_response(query):\n    # Retrieve relevant context for the query\n    context = retrieve_context(query)\n    # Log the query and context for debugging\n    logger.info(f\"Query: {query}\")\n    logger.info(f\"Retrieved Context: {context}\")\n    # Format the prompt to limit the response to the context",
        "detail": "core.chatbot_core_gemini",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "core.chatbot_core_gemini",
        "description": "core.chatbot_core_gemini",
        "peekOfCode": "model = genai.GenerativeModel(\"gemini-1.5-flash\")\ndef generate_response(query):\n    # Retrieve relevant context for the query\n    context = retrieve_context(query)\n    # Log the query and context for debugging\n    logger.info(f\"Query: {query}\")\n    logger.info(f\"Retrieved Context: {context}\")\n    # Format the prompt to limit the response to the context\n    formatted_prompt = (\n        f\"Use only the information provided in the following context to answer the query.\\n\\n\"",
        "detail": "core.chatbot_core_gemini",
        "documentation": {}
    },
    {
        "label": "fetch_gitlab_data",
        "kind": 2,
        "importPath": "core.data_retrieval",
        "description": "core.data_retrieval",
        "peekOfCode": "def fetch_gitlab_data(url):\n    response = requests.get(url)\n    if response.status_code == 200:\n        soup = BeautifulSoup(response.text, 'html.parser')\n        sections = []\n        # Identify headers to create meaningful chunks\n        for header in soup.find_all(['h2', 'h3']):  # Adjust based on HTML structure\n            content = []\n            for sibling in header.find_next_siblings():\n                if sibling.name in ['h2', 'h3']:",
        "detail": "core.data_retrieval",
        "documentation": {}
    },
    {
        "label": "handbook_data",
        "kind": 5,
        "importPath": "core.data_retrieval",
        "description": "core.data_retrieval",
        "peekOfCode": "handbook_data = fetch_gitlab_data('https://about.gitlab.com/company/')\ndirection_data =fetch_gitlab_data('https://about.gitlab.com/direction/')\n# Save the processed data to a JSON file\nwith open('data/gitlab_handbook.json', 'w') as f:\n    json.dump(handbook_data, f, indent=2)\nwith open('data/gitlab_direction.json', 'w') as f:\n    json.dump(direction_data, f, indent=2)\nprint(\"Data saved to data/gitlab_handbook.json\")\nprint(\"Data saved to data/gitlab_direction.json\")",
        "detail": "core.data_retrieval",
        "documentation": {}
    },
    {
        "label": "get_embeddings",
        "kind": 2,
        "importPath": "core.embedder",
        "description": "core.embedder",
        "peekOfCode": "def get_embeddings(texts):\n    return embedding_model.encode(texts, convert_to_tensor=True)",
        "detail": "core.embedder",
        "documentation": {}
    },
    {
        "label": "embedding_model",
        "kind": 5,
        "importPath": "core.embedder",
        "description": "core.embedder",
        "peekOfCode": "embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n# Function to get embeddings for text sections\ndef get_embeddings(texts):\n    return embedding_model.encode(texts, convert_to_tensor=True)",
        "detail": "core.embedder",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "core.logging_config",
        "description": "core.logging_config",
        "peekOfCode": "logger = logging.getLogger(\"chatbot_logger\")",
        "detail": "core.logging_config",
        "documentation": {}
    },
    {
        "label": "load_data_handbook",
        "kind": 2,
        "importPath": "core.retrieval_langchain",
        "description": "core.retrieval_langchain",
        "peekOfCode": "def load_data_handbook():\n    with open('data/gitlab_handbook.json', 'r') as f:\n        handbook_data = json.load(f)\n    return handbook_data\ndef load_data_direction():\n    with open('data/gitlab_direction.json', 'r') as f:\n        direction_data = json.load(f)\n    return direction_data\nembedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\nhf_embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")",
        "detail": "core.retrieval_langchain",
        "documentation": {}
    },
    {
        "label": "load_data_direction",
        "kind": 2,
        "importPath": "core.retrieval_langchain",
        "description": "core.retrieval_langchain",
        "peekOfCode": "def load_data_direction():\n    with open('data/gitlab_direction.json', 'r') as f:\n        direction_data = json.load(f)\n    return direction_data\nembedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\nhf_embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\ndef build_vector_store(data, name):\n    documents = [Document(page_content=f\"{item['header']} - {item['content']}\") for item in data]\n    logger.info(f\"Total documents indexed in {name}: {len(documents)}\")\n    vector_store = FAISS.from_documents(documents, hf_embeddings)",
        "detail": "core.retrieval_langchain",
        "documentation": {}
    },
    {
        "label": "build_vector_store",
        "kind": 2,
        "importPath": "core.retrieval_langchain",
        "description": "core.retrieval_langchain",
        "peekOfCode": "def build_vector_store(data, name):\n    documents = [Document(page_content=f\"{item['header']} - {item['content']}\") for item in data]\n    logger.info(f\"Total documents indexed in {name}: {len(documents)}\")\n    vector_store = FAISS.from_documents(documents, hf_embeddings)\n    return vector_store\n# Build vector stores separately\nvector_store_handbook = build_vector_store(load_data_handbook(), \"handbook\")\nvector_store_direction = build_vector_store(load_data_direction(), \"direction\")\ndef retrieve_context(query):\n    # Retrieve top 3 relevant documents from each vector store",
        "detail": "core.retrieval_langchain",
        "documentation": {}
    },
    {
        "label": "retrieve_context",
        "kind": 2,
        "importPath": "core.retrieval_langchain",
        "description": "core.retrieval_langchain",
        "peekOfCode": "def retrieve_context(query):\n    # Retrieve top 3 relevant documents from each vector store\n    retriever1 = vector_store_handbook.as_retriever()\n    results1 = retriever1.get_relevant_documents(query)[:3]\n    retriever2 = vector_store_direction.as_retriever()\n    results2 = retriever2.get_relevant_documents(query)[:3]\n    # Log retrieved documents for debugging\n    logger.info(f\"Retrieved Documents for Query from handbook '{query}': {[doc.page_content for doc in results1]}\")\n    logger.info(f\"Retrieved Documents for Query from direction '{query}': {[doc.page_content for doc in results2]}\")\n    # Combine the content of the retrieved documents",
        "detail": "core.retrieval_langchain",
        "documentation": {}
    },
    {
        "label": "embedding_model",
        "kind": 5,
        "importPath": "core.retrieval_langchain",
        "description": "core.retrieval_langchain",
        "peekOfCode": "embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\nhf_embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\ndef build_vector_store(data, name):\n    documents = [Document(page_content=f\"{item['header']} - {item['content']}\") for item in data]\n    logger.info(f\"Total documents indexed in {name}: {len(documents)}\")\n    vector_store = FAISS.from_documents(documents, hf_embeddings)\n    return vector_store\n# Build vector stores separately\nvector_store_handbook = build_vector_store(load_data_handbook(), \"handbook\")\nvector_store_direction = build_vector_store(load_data_direction(), \"direction\")",
        "detail": "core.retrieval_langchain",
        "documentation": {}
    },
    {
        "label": "hf_embeddings",
        "kind": 5,
        "importPath": "core.retrieval_langchain",
        "description": "core.retrieval_langchain",
        "peekOfCode": "hf_embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\ndef build_vector_store(data, name):\n    documents = [Document(page_content=f\"{item['header']} - {item['content']}\") for item in data]\n    logger.info(f\"Total documents indexed in {name}: {len(documents)}\")\n    vector_store = FAISS.from_documents(documents, hf_embeddings)\n    return vector_store\n# Build vector stores separately\nvector_store_handbook = build_vector_store(load_data_handbook(), \"handbook\")\nvector_store_direction = build_vector_store(load_data_direction(), \"direction\")\ndef retrieve_context(query):",
        "detail": "core.retrieval_langchain",
        "documentation": {}
    },
    {
        "label": "vector_store_handbook",
        "kind": 5,
        "importPath": "core.retrieval_langchain",
        "description": "core.retrieval_langchain",
        "peekOfCode": "vector_store_handbook = build_vector_store(load_data_handbook(), \"handbook\")\nvector_store_direction = build_vector_store(load_data_direction(), \"direction\")\ndef retrieve_context(query):\n    # Retrieve top 3 relevant documents from each vector store\n    retriever1 = vector_store_handbook.as_retriever()\n    results1 = retriever1.get_relevant_documents(query)[:3]\n    retriever2 = vector_store_direction.as_retriever()\n    results2 = retriever2.get_relevant_documents(query)[:3]\n    # Log retrieved documents for debugging\n    logger.info(f\"Retrieved Documents for Query from handbook '{query}': {[doc.page_content for doc in results1]}\")",
        "detail": "core.retrieval_langchain",
        "documentation": {}
    },
    {
        "label": "vector_store_direction",
        "kind": 5,
        "importPath": "core.retrieval_langchain",
        "description": "core.retrieval_langchain",
        "peekOfCode": "vector_store_direction = build_vector_store(load_data_direction(), \"direction\")\ndef retrieve_context(query):\n    # Retrieve top 3 relevant documents from each vector store\n    retriever1 = vector_store_handbook.as_retriever()\n    results1 = retriever1.get_relevant_documents(query)[:3]\n    retriever2 = vector_store_direction.as_retriever()\n    results2 = retriever2.get_relevant_documents(query)[:3]\n    # Log retrieved documents for debugging\n    logger.info(f\"Retrieved Documents for Query from handbook '{query}': {[doc.page_content for doc in results1]}\")\n    logger.info(f\"Retrieved Documents for Query from direction '{query}': {[doc.page_content for doc in results2]}\")",
        "detail": "core.retrieval_langchain",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "genai-chatbot-env.bin.jp",
        "description": "genai-chatbot-env.bin.jp",
        "peekOfCode": "def main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('expression')\n    parser.add_argument('-f', '--filename',\n                        help=('The filename containing the input data.  '\n                              'If a filename is not given then data is '\n                              'read from stdin.'))\n    parser.add_argument('--ast', action='store_true',\n                        help=('Pretty print the AST, do not search the data.'))\n    args = parser.parse_args()",
        "detail": "genai-chatbot-env.bin.jp",
        "documentation": {}
    },
    {
        "label": "user_query",
        "kind": 5,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "user_query = st.text_input(\"Ask a question about GitLab:\")\nif st.button(\"Submit\"):\n    if user_query:\n        # Generate response with retrieved context\n        response = generate_response(user_query)\n        st.session_state.history.append({\"user\": user_query, \"response\": response})\n        # Display chat history\n        for interaction in st.session_state.history:\n            st.write(f\"**You:** {interaction['user']}\")\n            st.write(f\"**Bot:** {interaction['response']}\")",
        "detail": "app",
        "documentation": {}
    }
]